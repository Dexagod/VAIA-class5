<!DOCTYPE html>
<html lang="nl">
<head>
  <title></title>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">
  <link rel="stylesheet" href="_shared/styles/shower-ruben.css">
  <link rel="stylesheet" href="_shared/styles/web-fundamentals.css">

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <title>Web Querying</title>
</head>
<body class="shower list">
  <header class="caption">
    <h1>
      <a class="series" href="#title">VAIA Course</a><br>
      <a class="module" href="#title">Web Querying</a>
    </h1>
  </header>

  <div class="title slide" id="title">
    <h2>
      <a class="series" href="#title">VAIA Course</a><br>
      <a class="module" href="#title">Web Querying</a>
    </h2>
    <p>hosted by: 
      <br>
      <a href="https://pod.rubendedecker.be/profile/card#me">Ruben Dedecker</a>
      <br>
      <a href="https://github.com/woutslabbinck/">Wout Slabbinck</a>
    </p>
    <p class="affiliation">
      <a href="http://www.ugent.be/"><img  class="ugent"  src="_shared/images/logos/ugent.svg"  alt="Ghent University"></a>
      <a href="http://www.imec.be/"><img class="imec" src="_shared/images/logos/imec.svg" alt="imec"></a>
      <a href="http://idlab.ugent.be/"><img class="idlab" src="_shared/images/logos/idlab.svg" alt="IDLab"></a>
    </p>
  </div>

  <div class="slide title" id="overview">
    <h3>Linked Data from publication to query</h3>
    
    TODO:: Intro

    <footer class="notes">
    </footer>
  </div>

  <div class="slide " id="overview">
    <h2>Data publication on the Web</h2>
    <ul>
      <li class="no-next">The current Web provides scalability in amount of clients, not in amount data sources</li>
      <li class="no-next">There is no inherent scalability in the integration of APIs</li>
      <li class="no-next">Scalability comes from integration of data</li>
    </ul>

    <footer class="notes">
      Scalability on the Web is currently solved by centralization of data.
      Because of this centralization, data is stored within the context of their data silos, and a select number of APIs is provided that needs to be integrated to use the data.
      This way, clients working in the context of facebook data, know that a name value means the full name of the user as given by them. 
      By reading the documentation, it knows how to find images the user stored, images the user is tagged in and more, which is exposed over a limited set of APIs by facebook.
      In case now they want to include the same data from google, they have to start again from zero, learn the documentation and integrate the new API.
      Where this might be feasible for a small set of large centralized data silos, this approach is not scalable.




    </footer>
  </div>


  <div class="slide " id="web_scalability">
    <h2>A Web of API integration</h2>
    <ul>
      <li class="no-next">The current Web provides scalability in amount of clients, not in amount data sources</li>
      <li class="no-next">There is no inherent scalability in the integration of APIs</li>
      <li class="no-next">Scalability comes from integration of data</li>
    </ul>
  </div>

  <div class="slide " id="data_silos">
    <h2>Data Silos on the Web</h2>
    <img src="logos.png" style="height: 50vh;" />
  </div>

  <div class="slide " id="data_publishing_strategies">
    <h2>Linked Data Publishing strategies</h2>
    <ul>
      <li class="no-next">
        <a href="https://ruben.verborgh.org/blog/2021/12/23/reflections-of-knowledge/#universal-api">
          There is no universal API that satisfies the data selection needs of all clients
        </a>
      </li>
      <li class="no-next">
        API design needs to balance client data selection requirements with the capabilities of the data publisher.
      </li>
    </ul>
  </div>



  <div class="slide " id="publishing_strategies">
    <h2>Data Publishing strategies</h2>
    <ul>
      <li class="no-next">
        <a href="https://ruben.verborgh.org/blog/2021/12/23/reflections-of-knowledge/#universal-api">
          There is no universal API that satisfies the data selection needs of all clients
        </a>
      </li>
      <li class="no-next">
        API design needs to balance client data selection requirements with the capabilities of the data publisher.
      </li>
    </ul>
  </div>

  <div class="slide" id="important">
    <h2>!important</h2>
    TODO:: fix slide. link blog Ruben
    <ul>
      <li class="no-next">
        Clients are not limited to the server abstraction of data.
        Clients can use abstractions over the Server API.
      </li>
    </ul>
  </div>

  <div class="slide " id="linked_data_publishing">
    <h2>Linked Data Publishing</h2>
    <ul>
      <li>data dump
        <ul><li>provides an archive file with the entire dataset</li></ul>
      </li>
      <li>SPARQL endpoint
        <ul><li>provides a query endpoint</li></ul>
      </li>
      <li>Linked Data Fragments
        <ul><li>provides a fragmentation of the dataset</li></ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="publishing_data_dump">
    <h2>A data dump stores all triples of a dataset in one or more files</h2>
    <ul>
      <li class="no-next">
        Clients need to download the full archive
        <br>
        before they can query it.
        <ul><li>These can be several gigabytes.</li></ul>
      </li>
      <li class="no-next">
        They offer the client full flexibility
        <br>
        to choose how data is processed.
      </li>
      <li class="no-next">
        Keeping data up-to date requires effort.
        <ul><li>
          redownload the entire dump <br>
          and apply incremental patches
        </li></ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="data-dump-example">
    <h2>
      A&nbsp;data dump places all dataset triples<br>
      in one or more archive files.
    </h2>
    <iframe class="website" src="https://downloads.dbpedia.org/2016-04/core/"></iframe>
  </div>
  
  <div class="slide" id="sparql-endpoint">
    <h2>
      A&nbsp;SPARQL endpoint lets clients evaluate<br>
      arbitrary (read-only) queries on a&nbsp;server.
    </h2>
    <ul>
      <li class="no-next">
        This gives clients direct access to<br>
        (only) the data they are interested in.
        <ul>
          <li>Only very little bandwidth is required.</li>
        </ul>
      </li>
      <li class="no-next">
        Data is always up-to-date.
      </li>
      <li class="no-next">
        The per-request cost for SPARQL endpoints<br>
        is much higher than for other HTTP servers.
        <ul>
          <li>Few servers allow arbitrarily complicated queries.</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide" id="sparql-endpoint-example">
    <h2>
      A&nbsp;SPARQL endpoint lets clients evaluate<br>
      arbitrary (read-only) queries on a&nbsp;server.
    </h2>
    <iframe class="website" src="https://dbpedia.org/sparql"></iframe>
  </div>


  <div class="slide " id="publishing_solid">
    <h2>Solid: Linked Data Platform (LDP)</h2>
    <ul>
      <li class="no-next">
        <a href="https://www.w3.org/TR/ldp/">Linked Data Platform</a>: read-write architecture for Linked Data using HTTP operations
      </li>
      <li class="no-next">
        LDP RDF Resources
        <ul>
          <li>resources that are represented by RDF</li>
          <li>LDP Container: special type of LDP Resource that contains links to other resources (comparable to a directory)</li>
        </ul>
      </li>
    </ul>
  </div>

  <div class="slide " id="publishing_solid-example">
    <h2>Solid: Linked Data Platform (LDP)</h2>
    <iframe class="website" src="https://woutslabbinck.inrupt.net/"></iframe>
  </div>

  <div class="slide " id="publishing_tree_ldes">
    <h2>TREE Hypermedia - Linked Data Event Streams (LDES)</h2>
    <ul>
      <li class="no-next">
        <a href="https://w3id.org/tree/specification">TREE Hypermedia Specification</a>
        <ul>
          <li>Collection of RDF items (members)</li>
          <li>Hypermedia relations to query the collection</li>
        </ul>
      </li>
      <li class="no-next">
        <a href="https://w3id.org/ldes/specification">Linked Data Event Stream</a> 
        <ul>
          <li>Extension of a TREE collection where each member is immutable</li>
          <li>
      </li>
    </ul>
  </div>

  <div class="slide " id="publishing_tree_ldes-example">
    <h2>TREE Hypermedia - Linked Data Event Streams (LDES)</h2>
    TODO: maybe use Pieter C slides? -> this demo currently sucks...
    <iframe class="website" src="https://treecg.github.io/TREE-LDES-visualizer/"></iframe>
  </div>

  <div class="slide " id="publishing_tpf">
    <h2>Triple Pattern Fragments</h2>
  </div>
  
  <div class="slide " id="publishing_sparql">
    <h2>SPARQL endpoint</h2>
  </div>
  
  <div class="slide " id="querying_interfaces">
    <h2>Linked Data querying interfaces</h2>
  </div>
  
  <div class="slide " id="querying_interfaces_data_dump">
    <h2>Querying a data dump</h2>
    <ul>
      <li class="no-next">Download the data dump</li>
      <li class="no-next">Load the files using a library such as <a href="https://github.com/rdfjs/N3.js">N3.js</a></li>
      <li class="no-next">Query the data using the library</li>
    </ul>
  </div>

  <div class="slide " id="querying_interfaces_data_dump-downsides">
    <h2>Querying a data dump</h2>
    <ul>
      <li class="no-next">
        Downsides
        <ul>
          <li class="no-next">Requires downloading all the data - even when you only are interested in a small part</li>
          <li class="no-next">New version? A full download of the new version is required or incremental patches have to be applied</li>
        </ul>
      </li>
      <!-- Any pros we can think of? Maybe full flexibility, but that was already in the previous slide -->
    </ul>
  </div>
 
  <div class="slide " id="querying_interfaces_data_dump-example">
    <h2>Querying a data dump: javascript example</h2>
    <pre><code>
      const response = await fetch(sourceUrl);
      const text = await response.text();
      const textStream = streamifyString(text);
      const quadStream = rdfParser.parse(textStream,
        {contentType: 'text/turtle'});
      const store = await storeStream(quadStream);

      store.getQuads()
    </code></pre>
    <footer class="notes">
      First, the data dump is downloaded using the fetch method. This executes an HTTP GET to the source.
      The second step serializes the body from the response into a string.
      Line 3 to 5 convert the string to an N3 Store.
      Finally, we can actually process/query the data using the N3 functions.
    </footer>
  </div>

  <div class="slide " id="querying_interfaces_solid">
  <h2>Querying a Solid pod</h2>
  <ul>
    <li class="no-next">A solid pod contains documents
      <ul>
        <li class="no-next">Each document can be queried like a data dump</li>
        <li class="no-next">Due to authorization, you can only download what you are allowed to read</li>
      </ul>
    </li>
    <li class="no-next">A solid pod allows for building systems
      <ul>
        <li class="no-next">Data can be written to a solid pod (in contrast to a data dump)</li>
      </ul>
    </li>
  </ul>
  </div>

  <div class="slide " id="querying_interfaces_solid-example">

  </div>

  <div class="slide " id="querying_interfaces_ldes">
    <h2>Querying an LDES</h2>
  </div>

  <div class="slide " id="querying_interfaces_ldes-example">
    <h2>Querying an LDES</h2>
    <iframe class="website" src="https://tree.linkeddatafragments.org/demo/autocompletion/"></iframe>
  </div>

  <div class="slide " id="querying_interfaces_sparql">
    <h2>Querying a SPARQL endpoint</h2>
  </div>

  <script src="_shared/scripts/shower.min.js"></script>
  <script src="_shared/scripts/enhancements.js"></script>
</body>
</html>
